{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvore de decisão aplicada na base Íris\n",
    "\n",
    "Agora com as partições A, B e C, podemos aplicar o algoritmo de árvore de decisão com a métrica de entropia. \n",
    "\n",
    "Teoricamente, a equação de entropia é dada por:\n",
    "\n",
    "$$\n",
    "\\text{Entropia}(S) = -\\sum_{i=1}^{n} p_i \\log_2 p_i\n",
    "$$\n",
    "\n",
    "Na própria documentação do scikit learn [aqui](https://scikit-learn.org/stable/modules/tree.html#classification-criteria) podemos ver que para o critério de entropia o mesmo cálculo é adotado. \n",
    "\n",
    "Usando-se a entropia, podemos calcular o ganho de cada variável. A que tiver o maior ganho, será usada para o nó inicial de decisão. O processo de calcular o ganho precisa ser repetido para a geração de cada novo nó, isolando-se as amostras que são filtradas pelo pai desses nós.\n",
    "\n",
    "Vamos carregar os nossos datasets abaixo e construir a árvore de decisão, para os três experimentos, assim como pede a especificação do segundo trabalho.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro: Treinamento (A+B) e Teste (C)\n",
    "\n",
    "carregar todos os datasets primeiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "A = pd.read_csv('../Iris/df_A.csv', header=None)\n",
    "B = pd.read_csv('../Iris/df_B.csv', header=None)\n",
    "C = pd.read_csv('../Iris/df_C.csv', header=None)\n",
    "\n",
    "# Set the first row as the header\n",
    "A.columns = A.iloc[0]\n",
    "B.columns = B.iloc[0]\n",
    "C.columns = C.iloc[0]\n",
    "\n",
    "# Drop the first row now that the headers are set\n",
    "A = A.drop(A.index[0])\n",
    "B = B.drop(B.index[0])\n",
    "C = C.drop(C.index[0])\n",
    "\n",
    "# Reset the index if needed\n",
    "A.reset_index(drop=True, inplace=True)\n",
    "B.reset_index(drop=True, inplace=True)\n",
    "C.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, os cálculos de acurácia, sensitividade, especificidade e precisão, seguindo essa ordem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Concatenate datasets A and B to form the training set\n",
    "# the X_train contains \n",
    "X_train = pd.concat([A.iloc[:, :-1], B.iloc[:, :-1]], ignore_index=True)\n",
    "y_train = pd.concat([A.iloc[:, -1], B.iloc[:, -1]], ignore_index=True)\n",
    "\n",
    "# Use dataset C as the test set\n",
    "X_test = C.iloc[:, :-1]\n",
    "y_test = C.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Create and fit the decision tree classifier\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output the accuracy\n",
    "print(f\"Acurácia: {accuracy:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos alguns jeitos de gerar a métrica de precisão. Os dados dessa base são balanceados, com o mesmo número de instâncias de cada espécie. Nesses casos, o tipo \"macro\" é o mais adequado. Essa métrica trata todas as classes igualmente, dando um peso igual para cada uma, sem considerar as frequências.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Assuming y_test are the true labels and y_pred are the model predictions\n",
    "precision = precision_score(y_test, y_pred, average='macro')  # Use 'micro', 'macro', or 'weighted' depending on your need\n",
    "\n",
    "print(f\"Precisão: {precision:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sensitividade (ou recall) é a medida do quão bom um modelo é em identificar os positivos verdadeiros para os casos positivos de fato das amostras. Ele é calculado como o número de positivos verdadeiros divididos pelo número de todas as amostras relevantes. Ou seja, todas as amostras que deviam ser identificadas como positivas. \n",
    "\n",
    "No contexto da base, sensitividade trata da capacidade de identificar corretamente Iris-setosa, por exemplo, quando ela o é de fato. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitividade: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Assuming y_test are the true labels and y_pred are the model predictions\n",
    "sensitivity = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Sensitividade: {sensitivity:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A especificidade mede o quão bem o modelo identifica as outras espécies (que seriam os casos negativos quando estamos focados em detectar Iris-setosa) corretamente. Ou seja, quando o modelo prevê que uma flor não é Iris-setosa, a especificidade nos diz quantas vezes essa previsão está correta, indicando que a flor é realmente uma Iris-versicolor ou Iris-virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Especificidade por classe: [1.0, 0.9444444444444444, 0.9444444444444444]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test are the true labels and y_pred are the model predictions\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# For a multi-class classification, like the Iris dataset, calculate specificity for each class\n",
    "specificity_per_class = []\n",
    "for i in range(len(cm)):\n",
    "    tn = cm[0, 0] + cm[1, 1] - cm[i, i]\n",
    "    fp = cm[i, :].sum() - cm[i, i]\n",
    "    specificity_i = tn / (tn + fp)\n",
    "    specificity_per_class.append(specificity_i)\n",
    "\n",
    "print(f\"Especificidade por classe: {specificity_per_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
